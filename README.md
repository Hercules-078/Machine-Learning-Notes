# Machine-Learning-Notes

## **Mathematics**

- [x] Vector Spaces and Subspaces
- [x] Linear Transformations, eigenvalues and eigenvectors
- [x] Orthogonality, Projection and Real symmetric matrices
- [x] Singular value decomposition, Principal Component Analysis, Support Vector Machines and Applications
- [ ] Probability Foundations - From Events to Bayes’ Theorem
- [ ] Random Variables, Moments of Random Variables\
- [ ] Jointly Distributed Random Variables, Conditioning of Random variables
- [ ] Limit Theorems, Sample Geometry, Covariance Matrices and Properties
- [ ] Taylor’s series, Partial Derivatives, Chain rule, Gradient, Jacobian, Hessian
- [ ] Matrix Derivatives, Gradient Descent and Stochastic Gradient Descent, Constrained and Unconstrained optimization, Lagrangian, Least Squares and PCA
- [ ] Neural Nets, Perceptron, Back Propagation Algorithm
- [ ] Algorithms for ML - Classification, Clustering and Regression
---

## **Regression Analysis**
- [x] Simple Linear Regression
- [x] Multiple Linear Regression
- [x] Regularization
- [x] Multicollinearity
- [ ] Polynomial Linear Regression
- [x] Gradient descent

